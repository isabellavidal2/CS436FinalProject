{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkEY7FwKHUsNKCXWg/dLFO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDKf2N-FcOEL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "#selecting gpu instead of cpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "# Setting random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "Using device: cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ESM_Tracker:\n",
        "    #track Estimation Shift Magnitude during training\n",
        "    def __init__(self):\n",
        "        self.expected_stats = {}\n",
        "        self.estimated_stats = {}\n",
        "        self.esm_history = {}\n",
        "\n",
        "    def update_expected(self, layer_name, input_data):\n",
        "        \"\"\"Calculate expected statistics on current batch\"\"\"\n",
        "        if layer_name not in self.expected_stats:\n",
        "            self.expected_stats[layer_name] = {'mean': [], 'var': []}\n",
        "\n",
        "        #calculate the statistics for current batch (what we \"expect\")\n",
        "        if len(input_data.shape) == 4:  # CNN case\n",
        "            mean = input_data.mean(dim=(0, 2, 3))\n",
        "            var = input_data.var(dim=(0, 2, 3))\n",
        "        else:  # MLP case\n",
        "            mean = input_data.mean(dim=0)\n",
        "            var = input_data.var(dim=0)\n",
        "\n",
        "        self.expected_stats[layer_name]['mean'].append(mean.detach())\n",
        "        self.expected_stats[layer_name]['var'].append(var.detach())\n",
        "\n",
        "    def update_estimated(self, layer_name, bn_layer):\n",
        "        \"\"\"Get estimated statistics from BN running averages\"\"\"\n",
        "        if layer_name not in self.estimated_stats:\n",
        "            self.estimated_stats[layer_name] = {'mean': [], 'var': []}\n",
        "\n",
        "        self.estimated_stats[layer_name]['mean'].append(bn_layer.running_mean.detach().clone())\n",
        "        self.estimated_stats[layer_name]['var'].append(bn_layer.running_var.detach().clone())\n",
        "\n",
        "    def calculate_esm(self, layer_name):\n",
        "        \"\"\"Calculate Estimation Shift Magnitude\"\"\"\n",
        "        if layer_name not in self.expected_stats or layer_name not in self.estimated_stats:\n",
        "            return 0, 0\n",
        "\n",
        "        #use the most recent statistics\n",
        "        exp_mean = self.expected_stats[layer_name]['mean'][-1]\n",
        "        exp_var = self.expected_stats[layer_name]['var'][-1]\n",
        "        est_mean = self.estimated_stats[layer_name]['mean'][-1]\n",
        "        est_var = self.estimated_stats[layer_name]['var'][-1]\n",
        "\n",
        "        esm_mean = torch.norm(exp_mean - est_mean, p=2).item()\n",
        "        esm_var = torch.norm(torch.sqrt(exp_var + 1e-5) - torch.sqrt(est_var + 1e-5), p=2).item()\n",
        "\n",
        "        #store history\n",
        "        if layer_name not in self.esm_history:\n",
        "            self.esm_history[layer_name] = {'mean': [], 'var': []}\n",
        "\n",
        "        self.esm_history[layer_name]['mean'].append(esm_mean)\n",
        "        self.esm_history[layer_name]['var'].append(esm_var)\n",
        "\n",
        "        return esm_mean, esm_var\n",
        "\n",
        "class XBNBlock(nn.Module):\n",
        "    \"\"\"XBNBlock with BFN at position 2 (P2)\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1, bfn_type='GN'):\n",
        "        super(XBNBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels//4, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels//4)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels//4, out_channels//4, 3, stride=stride, padding=1, bias=False)\n",
        "        #this is where we put BFN instead of BN (XBNBlock-P2, meaning Position 2 placement)\n",
        "        if bfn_type == 'GN':\n",
        "            self.norm2 = nn.GroupNorm(32, out_channels//4)  #GroupNorm as BFN\n",
        "        else:  #InstanceNorm\n",
        "            self.norm2 = nn.InstanceNorm2d(out_channels//4)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels//4, out_channels, 1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.norm2(self.conv2(out)))  #BFN here\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "KIxb9PhxccDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7F8D9oudccM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}